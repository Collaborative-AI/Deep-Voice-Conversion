defaults:
    - model: default
    - training: cpc

resume: False
checkpoint_dir: checkpoints

mi_weight: 0.01
mi_lr: 3e-4
mi_iters: 5

sampling: sameSeq
train_file: train
valid_file: valid

use_CSMI: True  # use MI between content and speaker

training:
    sample_frames: 128
    batch_size: 256
    n_speakers_per_batch: 256
    n_utterances_per_speaker: 8
    n_prediction_steps: 6
    n_negatives: 10
    n_epochs: 500
    scheduler:
        warmup_epochs: 10
        initial_lr: 1e-6
        max_lr: 1e-3
        gamma: 0.5
        milestones:
            - 300
            - 400
            - 500
    checkpoint_interval: 50
    n_workers: 4
    log_interval: 50

model:
    encoder_content:
      in_channels: 80
      channels: 512
      n_embeddings: 512
      z_dim: 64
      c_dim: 256
    encoder_style:
      style_hidden: 128
      style_head: 6
      style_kernel_size: 5
      style_vector_dim: 256
      in_channels: 80
      dropout: 0.1
    cpc:
      sample_frames: 128
      batch_size: 256
      n_speakers_per_batch: 256
      n_utterances_per_speaker: 8
      n_prediction_steps: 6
      n_negatives: 10
      n_epochs: 500
      scheduler:
          warmup_epochs: 10
          initial_lr: 1e-6
          max_lr: 1e-3
          gamma: 0.5
          milestones:
              - 300
              - 400
              - 500
      checkpoint_interval: 50
      n_workers: 4
      log_interval: 50
    cpc_model:
        nPredicts: 12
        dimOutputAR: 256
        dimOutputEncoder: 64
        negativeSamplingExt: 64
        rnnMode: ffd
        dropout: False
        speakerEmbedding: 0
        nSpeakers: 0
        sizeInputSeq: 64
    contrastive_model:
      text_encoder: bert
      joint_embed: 256
      training:
        margin: 0.2
        freeze: True
        loss: contrastive  # 'triplet', 'weight', 'ntxent'
        spec_augmentation: True
        epochs: 50
        lr: !!float 1e-4
        clip_grad: 2
        seed: 20
        resume: False
        l2_norm: True
        dropout: 0.2
      bert_encoder:
        type: 'bert-base-uncased'
        freeze: True
    cross_modal_decoder:
      # "dataset": "LibriTTS",
      # "n_speakers": 1124,

      # "text_cleaners": ["english_cleaners"],
      
      # "sampling_rate": 16000,
      # "filter_length": 1024,
      # "hop_length": 256,
      # "win_length": 1024,
      # "max_wav_value": 32768.0,
      # "mel_fmin": 0.0,
      # "mel_fmax": 8000.0,
      # "n_mel_channels": 80,
      max_seq_len: 1000

      encoder_layer: 4,
      encoder_head: 2,
      encoder_hidden: 256,
      # "decoder_layer": 4
      # "decoder_head": 2
      decoder_hidden: 256
      fft_conv1d_filter_size: 1024
      fft_conv1d_kernel_size: [9, 1]
      dropout: 0.1

      # "variance_predictor_filter_size": 256,
      # "variance_predictor_kernel_size": 3,
      # "variance_embedding_kernel_size": 3,
      # "variance_dropout": 0.5,

      # "style_hidden": 128,
      # "style_head": 2,
      # "style_kernel_size": 5,
      style_vector_dim: 256

      # "batch_size": 48,
      # "meta_batch_size": 20,
      # "max_iter": 200000,
      # "meta_iter": 40000,
      # "n_warm_up_step": 4000,
      # "grad_clip_thresh": 1.0,

      # "betas":[0.9, 0.98],
      # "eps":1e-9
